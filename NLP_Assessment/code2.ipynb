{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2  FIT5212 \n",
    "# Recommender System\n",
    "\n",
    "**Student Name:**  Eddy\n",
    "\n",
    "**Student ID:**    33495608\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required library\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#Command to install the surprise library if it's not available\n",
    "#!pip install surprise\n",
    "\n",
    "from surprise import Reader, Dataset, SVD, KNNBasic\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "reader = Reader()\n",
    "\n",
    "#Setting the seed for the entire code\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the dataset\n",
    "\n",
    "The dataset will be processed to be used for the KNN and SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the train dataset \n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "#Making a copy of the train  dataset to be preprocessed\n",
    "df_train_p = df_train.copy()\n",
    "\n",
    "#Checking if it's copied properly\n",
    "df_train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the train dataset then check if it's loaded properly\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "#Making a copy of the test dataset to be preprocessed\n",
    "df_test_p = df_test.copy()\n",
    "\n",
    "#Checking if it's copied properly\n",
    "df_test_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing Exploratory Data Analysis to see the shape of the train dataset\n",
    "print('The row and columns for the df_train is =', df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing Exploratory Data Analysis to see the info of the train dataset\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the distribution of the ratings column\n",
    "print('The rating column consist of =', df_train['rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking if there's any NaN in any of the columns\n",
    "print('Checking if any of the column has missing values')\n",
    "df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the product id for a specific product name\n",
    "prod_big = df_train[df_train['product_name'].isin(['Big'])][['user_id','product_id','product_name']]\n",
    "\n",
    "print(\"The Big product name is associated with product id which is\")\n",
    "prod_big['product_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the EDA on the Big product name, there are 3 product id that is associated with Big product name. This violates Amazon rule since a single product name must only have 1 product id.\n",
    "\n",
    "To resolve this issue, the most voted product id by product name is chosen as the correct product id for that product name. This wrangling is applied to both train and test dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the product_name then find the product_id with the most votes\n",
    "most_voted_id = df_train_p.groupby(['product_name', 'product_id'])['votes'].max()\n",
    "most_voted_id = most_voted_id.groupby(level=0).idxmax().apply(lambda x: x[1])\n",
    "\n",
    "# Converting the result to dictionary\n",
    "product_name_to_id = most_voted_id.to_dict()\n",
    "\n",
    "# Map the 'product_name' to the 'product_id' with the most votes\n",
    "df_train_p['product_id'] = df_train_p['product_name'].map(product_name_to_id)\n",
    "\n",
    "# Applying the dictionary to the other dataset\n",
    "df_test_p['product_id'] = df_test_p['product_name'].map(product_name_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing the rating through the reader class from Surprise package\n",
    "#This is to make a user based collaborative filtering\n",
    "data = Dataset.load_from_df(df_train[['user_id', 'product_id', 'rating']], reader) #Pre-processed data\n",
    "data_p = Dataset.load_from_df(df_train_p[['user_id', 'product_id', 'rating']], reader) #Processed data\n",
    "\n",
    "#Parsing the rating through the reader class from Surprise package\n",
    "#The order of user and product is reversed therefore this is to make an item based collaborative filtering\n",
    "data_rev = Dataset.load_from_df(df_train[['product_id', 'user_id', 'rating']], reader) #Pre-processed data\n",
    "data_rev_p = Dataset.load_from_df(df_train_p[['product_id', 'user_id', 'rating']], reader) #Processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the algorithm K-Nearest Neighbor and its optimization will be performed to predict the rating. First the pre-processed data will be used\n",
    "\n",
    "**Note that because KNN and Cross Validation from Surprise library didn't allow for random state, the result will be slightly different each time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# The base KNN algorithm from surprise package is loaded\n",
    "algo_knn = KNNBasic()\n",
    "# The algorithm is run on the pre-processed datawith 5 CV and the evaluation metric is printed (RMSE, MAE)\n",
    "cross_validate(algo_knn, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "#Setting up the dictionary to explore the best parameter\n",
    "#For the purpose of this code, only the optimal parameter is supplied here\n",
    "dict = {'k': [20], 'min_k' : [3]}\n",
    "\n",
    "#Loading up the gridsearchcv algorithm then run the algorithm on the pre-processed dataset\n",
    "grid_knn_pre = GridSearchCV(KNNBasic, dict, measures=['rmse', 'mae'], cv=5)\n",
    "grid_knn_pre.fit(data)\n",
    "\n",
    "#Printing the result\n",
    "print(\"Best RMSE score for pre-processed data:\", round(grid_knn_pre.best_score['rmse'],4))\n",
    "print(\"Best parameters for RMSE:\", grid_knn_pre.best_params['rmse'])\n",
    "\n",
    "print(\"Best MAE score for pre-processed data:\", round(grid_knn_pre.best_score['mae'],4))\n",
    "print(\"Best parameters for MAE:\", grid_knn_pre.best_params['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of the KNN model to the PreProcessed Data**\n",
    "|Model| HyperParameter| RMSE | MAE |\n",
    "| --- | --- | --- | --- |\n",
    "|Base KNN | k = 40, min_k = 1 | 1.0181 | 0.7270 |\n",
    "|Finetuned KNN | k = 20, min_k = 3 | 0.9576 | 0.7103 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the model is applied to the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# The algorithm is run on the processed data with 5 CV and the evaluation metric is printed (RMSE, MAE)\n",
    "cross_validate(algo_knn, data_p, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "#Setting up the dictionary to explore the best parameter\n",
    "#For the purpose of this code, only the optimal parameter is supplied here\n",
    "dict = {'k': [20], 'min_k' : [3]}\n",
    "\n",
    "#Loading up the gridsearchcv algorithm then run the algorithm on the pre-processed dataset\n",
    "grid_knn_post = GridSearchCV(KNNBasic, dict, measures=['rmse', 'mae'], cv=5)\n",
    "grid_knn_post.fit(data_p)\n",
    "\n",
    "#Printing the result\n",
    "print(\"Best RMSE score for processed data:\", round(grid_knn_post.best_score['rmse'],4))\n",
    "print(\"Best parameters for RMSE:\", grid_knn_post.best_params['rmse'])\n",
    "\n",
    "print(\"Best MAE score for processed data:\", round(grid_knn_post.best_score['mae'],4))\n",
    "print(\"Best parameters for MAE:\", grid_knn_post.best_params['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of the KNN model to the Processed Data**\n",
    "\n",
    "|Model| HyperParameter| RMSE | MAE |\n",
    "| --- | --- | --- | --- |\n",
    "|Base KNN | k = 40, min_k = 1 | 0.9616 | 0.6713 |\n",
    "|Finetuned KNN | k = 20, min_k = 3 | 0.9057 | 0.6517 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the train data to be able to parsed into the algorithm\n",
    "trainset_pre = data.build_full_trainset()\n",
    "trainset_post = data_p.build_full_trainset()\n",
    "\n",
    "#Fitting the preprocessed and processed train dataset into the KNN algorithm\n",
    "#The hyperparameter is set to the finetuned KNN\n",
    "pred_knn = KNNBasic(k = 20, min_k = 3 ).fit(trainset_pre)\n",
    "pred_knn_post = KNNBasic(k = 20, min_k = 3 ).fit(trainset_post)\n",
    "\n",
    "#Copying the test dataset\n",
    "df_test_knn = df_test.copy()\n",
    "df_test_p_knn = df_test_p.copy()\n",
    "\n",
    "#Applying the model to the preprocessed and processed test dataset\n",
    "df_test_knn['rating'] = df_test_knn.apply(lambda x : pred_knn.predict(x.user_id, x.product_id).est, axis = 1)\n",
    "df_test_p_knn['rating'] = df_test_p_knn.apply(lambda x : pred_knn_post.predict(x.user_id, x.product_id).est, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the irrelevant column and writing to csv file for preprocessed dataset\n",
    "df_test_knn = df_test_knn.drop(columns=['user_id', 'product_id', 'product_name'])\n",
    "df_test_knn.to_csv('KNN_predictions_pre.csv', index=False)\n",
    "\n",
    "#Dropping the irrelevant column and writing to csv file for processed dataset\n",
    "df_test_p_knn = df_test_p_knn.drop(columns=['user_id', 'product_id', 'product_name'])\n",
    "df_test_p_knn.to_csv('KNN_predictions_post1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Score**\n",
    "\n",
    "|Model|Processed | HyperParameter| Score |\n",
    "| --- | --- | --- | --- | \n",
    "|Base KNN | No | k = 40, min_k = 1 | 1.03142 |\n",
    "|Finetuned KNN | No | k = 20, min_k = 3 | 0.96901 |\n",
    "|Base KNN | Yes | k = 40, min_k = 1 |  0.98305 |\n",
    "|Finetuned KNN | Yes | k = 20, min_k = 3 | 0.92402 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD\n",
    "\n",
    "In this section, the algorithm Singular Value Decomposition and its optimization will be performed to predict the rating. First the pre-processed data will be used\n",
    "\n",
    "**Note that because Cross Validation from Surprise library didn't allow for random state, the result will be slightly different each time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# Loading the base SVD model\n",
    "algo_svd = SVD(random_state=42)\n",
    "# Running the base SVD model with cross validation to get the RMSE and MAE\n",
    "cross_validate(algo_svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "#Setting up the dictionary to explore the best parameter\n",
    "#For the purpose of this code, only the optimal parameter is supplied here\n",
    "dict = {'n_factors': [200], 'lr_all' : [0.1], 'reg_all' : [0.022], 'n_epochs' : [150], 'random_state' : [42]}\n",
    "\n",
    "#Loading up the gridsearchcv algorithm then run the algorithm on the pre-processed dataset\n",
    "grid_svd_pre = GridSearchCV(SVD, dict, measures=['rmse', 'mae'], cv=5)\n",
    "grid_svd_pre.fit(data)\n",
    "\n",
    "#Printing the result\n",
    "print(\"Best RMSE score for pre-processed data:\", round(grid_svd_pre.best_score['rmse'],4))\n",
    "print(\"Best parameters for RMSE:\", grid_svd_pre.best_params['rmse'])\n",
    "\n",
    "print(\"Best MAE score for pre-processed data:\", round(grid_svd_pre.best_score['mae'],4))\n",
    "print(\"Best parameters for MAE:\", grid_svd_pre.best_params['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of the SVD model to the PreProcessed Data**\n",
    "\n",
    "|Model| HyperParameter| RMSE | MAE |\n",
    "| --- | --- | --- | --- |\n",
    "|Base SVD | n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02 | 0.9381 | 0.6936 |\n",
    "|Finetuned SVD | n_factors=200, n_epochs=150, lr_all=0.1, reg_all=0.022 | 0.8668 | 0.6285 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the processed dataset will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# Loading the base SVD model\n",
    "algo_svd = SVD(random_state=42)\n",
    "# Running the base SVD model with cross validation to get the RMSE and MAE\n",
    "cross_validate(algo_svd, data_p, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "#Setting up the dictionary to explore the best parameter\n",
    "#For the purpose of this code, only the optimal parameter is supplied here\n",
    "dict = {'n_factors': [200], 'lr_all' : [0.1], 'reg_all' : [0.022], 'n_epochs' : [150], 'random_state' : [42]}\n",
    "\n",
    "#Loading up the gridsearchcv algorithm then run the algorithm on the pre-processed dataset\n",
    "grid_svd_post = GridSearchCV(SVD, dict, measures=['rmse', 'mae'], cv=5)\n",
    "grid_svd_post.fit(data_p)\n",
    "\n",
    "#Printing the result\n",
    "print(\"Best RMSE score for pre-processed data:\", round(grid_svd_post.best_score['rmse'],4))\n",
    "print(\"Best parameters for RMSE:\", grid_svd_post.best_params['rmse'])\n",
    "\n",
    "print(\"Best MAE score for pre-processed data:\", round(grid_svd_post.best_score['mae'],4))\n",
    "print(\"Best parameters for MAE:\", grid_svd_post.best_params['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of the SVD model to the Processed Data**\n",
    "\n",
    "|Model| HyperParameter| RMSE | MAE |\n",
    "| --- | --- | --- | --- |\n",
    "|Base SVD | n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02 | 0.8679 | 0.6276 |\n",
    "|Finetuned SVD | n_factors=200, n_epochs=150, lr_all=0.1, reg_all=0.022 | 0.7964 | 0.5289 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the preprocessed and processed train dataset into the SVD algorithm\n",
    "#The hyperparameter is set to the finetuned SVD\n",
    "pred_svd = SVD(n_factors=200, lr_all=0.1, reg_all=0.022, n_epochs=150, random_state=42).fit(trainset_pre)\n",
    "pred_svd_post = SVD(n_factors=200, lr_all=0.1, reg_all=0.022, n_epochs=150, random_state=42).fit(trainset_post)\n",
    "\n",
    "#Copying the test dataset\n",
    "df_test_svd = df_test.copy()\n",
    "df_test_p_svd = df_test_p.copy()\n",
    "\n",
    "#Applying the model to the preprocessed and processed test dataset\n",
    "df_test_svd['rating'] = df_test_svd.apply(lambda x : pred_svd.predict(x.user_id, x.product_id).est, axis = 1)\n",
    "df_test_p_svd['rating'] = df_test_p_svd.apply(lambda x : pred_svd_post.predict(x.user_id, x.product_id).est, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the irrelevant column and writing to csv file for preprocessed dataset\n",
    "df_test_svd = df_test_svd.drop(columns=['user_id', 'product_id', 'product_name'])\n",
    "df_test_svd.to_csv('SVD_predictions_pre1.csv', index=False)\n",
    "\n",
    "#Dropping the irrelevant column and writing to csv file for processed dataset\n",
    "df_test_p_svd = df_test_p_svd.drop(columns=['user_id', 'product_id', 'product_name'])\n",
    "df_test_p_svd.to_csv('SVD_predictions_post1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Score**\n",
    "\n",
    "|Model|Processed | HyperParameter| Score |\n",
    "| --- | --- | --- | --- | \n",
    "|Base SVD | No |  n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02 | 0.96019 |\n",
    "|Finetuned SVD | No | n_factors=200, n_epochs=150, lr_all=0.1, reg_all=0.022 | 0.89576 |\n",
    "|Base SVD | Yes |  n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02 |  0.89279 |\n",
    "|Finetuned SVD | Yes | n_factors=200, n_epochs=150, lr_all=0.1, reg_all=0.022 | 0.83558 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, it's clear that SVD is the better model. Next is finetuning the combination of lr_all which is \n",
    "\n",
    "- lr_bu\n",
    "- lr_bi\n",
    "- lr_pu\n",
    "- lr qi\n",
    "\n",
    "and the combination of reg_all which is\n",
    "\n",
    "- reg_bu\n",
    "- reg_bi\n",
    "- reg_pu\n",
    "- reg_qi\n",
    "\n",
    "The hyperparameter is already found so it will be directly provided into the code. The other parameter will be matched to the finetuned hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "#Setting up the dictionary to explore the best parameter\n",
    "#For the purpose of this code, only the optimal parameter is supplied here\n",
    "dict = {'n_factors': [200], 'lr_bu' : [0.091], 'lr_bi' : [0.085], 'lr_pu' : [0.085], \n",
    "        'lr_qi' : [0.106], 'reg_all' : [0.022], 'n_epochs' : [150], 'random_state' : [42]}\n",
    "\n",
    "#Loading up the gridsearchcv algorithm then run the algorithm on the pre-processed dataset\n",
    "grid_svd_lr = GridSearchCV(SVD, dict, measures=['rmse', 'mae'], cv=5)\n",
    "grid_svd_lr.fit(data_p)\n",
    "\n",
    "#Printing the result\n",
    "print(\"Best RMSE score for finetuning lr data:\", round(grid_svd_lr.best_score['rmse'],4))\n",
    "print(\"Best parameters for RMSE:\", grid_svd_lr.best_params['rmse'])\n",
    "\n",
    "print(\"Best MAE score for finetuning lr data:\", round(grid_svd_lr.best_score['mae'],4))\n",
    "print(\"Best parameters for MAE:\", grid_svd_lr.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "#Setting up the dictionary to explore the best parameter\n",
    "#For the purpose of this code, only the optimal parameter is supplied here\n",
    "dict = {'n_factors': [200], 'reg_bu' : [0.021], 'reg_bi' : [0.02], 'reg_pu' : [0.022], \n",
    "        'reg_qi' : [0.022], 'lr_all' : [0.1], 'n_epochs' : [150], 'random_state' : [42]}\n",
    "\n",
    "#Loading up the gridsearchcv algorithm then run the algorithm on the pre-processed dataset\n",
    "grid_svd_reg = GridSearchCV(SVD, dict, measures=['rmse', 'mae'], cv=5)\n",
    "grid_svd_reg.fit(data_p)\n",
    "\n",
    "#Printing the result\n",
    "print(\"Best RMSE score for finetuning lr data:\", round(grid_svd_reg.best_score['rmse'],4))\n",
    "print(\"Best parameters for RMSE:\", grid_svd_reg.best_params['rmse'])\n",
    "\n",
    "print(\"Best MAE score for finetuning lr data:\", round(grid_svd_reg.best_score['mae'],4))\n",
    "print(\"Best parameters for MAE:\", grid_svd_reg.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# Loading the fine tuned SVD model to be used for the item-based collaborative filtering\n",
    "algo_svd_rev = SVD(n_factors=200, lr_bu=0.091, lr_bi=0.085, lr_pu=0.085, lr_qi=0.106, reg_all=0.022, n_epochs=200, random_state=42)\n",
    "# Running the base SVD model with cross validation to get the RMSE and MAE\n",
    "cross_validate(algo_svd_rev, data_rev_p, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD, further Learning Rates and Regularization finetuning**\n",
    "\n",
    "|Model| HyperParameter| RMSE | MAE |\n",
    "| --- | --- | --- | --- | \n",
    "|Finetuning LR |  lr_bu=0.091, lr_bi=0.085, lr_pu=0.085, lr_qi=0.106 | 0.7965 | 0.5308 |\n",
    "|Finetuning REG |  reg_bu=0.021, reg_bi=0.02, reg_pu=0.022, reg_qi=0.022 | 0.7985 | 0.5251 |\n",
    "|With Item-Based | n_factors=200, n_epochs=150, lr_all=0.1, reg_all=0.022 | 0.8070 | 0.5509 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that there is a diminishing return on the performance. Next we're going to average the user and item based rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the preprocessed and processed train dataset into the SVD algorithm\n",
    "#The hyperparameter is set to the finetuned SVD\n",
    "trainset_lr = data_p.build_full_trainset()\n",
    "trainset_lr_rev = data_rev_p.build_full_trainset()\n",
    "pred_lr = SVD(n_factors=200, lr_bu=0.091, lr_bi=0.085, lr_pu=0.085, lr_qi=0.106, n_epochs=150, random_state=42).fit(trainset_lr)\n",
    "pred_lr_rev = SVD(n_factors=200, lr_all=0.1, reg_all=0.022, n_epochs=150, random_state=42).fit(trainset_lr_rev)\n",
    "\n",
    "#Copying the test dataset\n",
    "df_test_lr = df_test_p.copy()\n",
    "df_test_rev_lr = df_test_p.copy()\n",
    "\n",
    "#Applying the model to the preprocessed and processed test dataset\n",
    "df_test_lr['rating'] = df_test_lr.apply(lambda x : pred_lr.predict(x.user_id, x.product_id).est, axis = 1)\n",
    "df_test_rev_lr['rating'] = df_test_rev_lr.apply(lambda x : pred_lr_rev.predict(x.product_id, x.user_id).est, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the irrelevant column for merging the dataset\n",
    "df_test_lr = df_test_lr.drop(columns=['user_id', 'product_id', 'product_name'])\n",
    "df_test_rev_lr = df_test_rev_lr.drop(columns=['user_id', 'product_id', 'product_name'])\n",
    "\n",
    "#Merge the dataset then average the rating, then see the result\n",
    "df_test_comb = pd.merge(df_test_lr, df_test_rev_lr, on='ID')\n",
    "df_test_comb['rating'] = df_test_comb[['rating_x','rating_y']].mean(axis=1)\n",
    "df_test_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the irrelevant column then save the prediction into a CSV\n",
    "df_test_comb = df_test_comb.drop(columns=['rating_x','rating_y'])\n",
    "df_test_comb.to_csv('combined_mean_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of user-based and item-based rating achieved a score of 0.82644 in Kaggle which is the best score when compared to the other score listed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
